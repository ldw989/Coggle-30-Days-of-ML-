{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coggle 30 Days of ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task1 Donwload & Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = pd.read_csv('data/used_car_train_20200313.csv', sep=' ')\n",
    "Test_data = pd.read_csv('data/used_car_testA_20200313.csv', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data shape: (150000, 31)\n",
      "Test_data shape: (50000, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train_data shape:\", Train_data.shape)\n",
    "print(\"Test_data shape:\", Test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task2 \n",
    "* 使用Pandas对比赛数据集进行分析分析\n",
    "    * 每个字段的取值、范围和类型\n",
    "    * 结合比赛页面中具体字段的含义，对字段的取值分布进行分析\n",
    "* 计算特征字段与标签的相关性\n",
    "* 选择特征字段中与标签强相关的3个字段，绘制其余标签的分布关系图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>20040402</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235676</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>0.129549</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.097462</td>\n",
       "      <td>-2.881803</td>\n",
       "      <td>2.804097</td>\n",
       "      <td>-2.420821</td>\n",
       "      <td>0.795292</td>\n",
       "      <td>0.914762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>20030301</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264777</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.135731</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-4.900482</td>\n",
       "      <td>2.096338</td>\n",
       "      <td>-1.030483</td>\n",
       "      <td>-1.722674</td>\n",
       "      <td>0.245522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>20040403</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251410</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.165147</td>\n",
       "      <td>0.062173</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>-4.846749</td>\n",
       "      <td>1.803559</td>\n",
       "      <td>1.565330</td>\n",
       "      <td>-0.832687</td>\n",
       "      <td>-0.229963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>19960908</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274293</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.121964</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.509599</td>\n",
       "      <td>1.285940</td>\n",
       "      <td>-0.501868</td>\n",
       "      <td>-2.438353</td>\n",
       "      <td>-0.478699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>20120103</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228036</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.091880</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>-1.896240</td>\n",
       "      <td>0.910783</td>\n",
       "      <td>0.931110</td>\n",
       "      <td>2.834518</td>\n",
       "      <td>1.923482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0       0     736  20040402   30.0      6       1.0       0.0      0.0     60   \n",
       "1       1    2262  20030301   40.0      1       2.0       0.0      0.0      0   \n",
       "2       2   14874  20040403  115.0     15       1.0       0.0      0.0    163   \n",
       "3       3   71865  19960908  109.0     10       0.0       0.0      1.0    193   \n",
       "4       4  111080  20120103  110.0      5       1.0       0.0      0.0     68   \n",
       "\n",
       "   kilometer  ...       v_5       v_6       v_7       v_8       v_9      v_10  \\\n",
       "0       12.5  ...  0.235676  0.101988  0.129549  0.022816  0.097462 -2.881803   \n",
       "1       15.0  ...  0.264777  0.121004  0.135731  0.026597  0.020582 -4.900482   \n",
       "2       12.5  ...  0.251410  0.114912  0.165147  0.062173  0.027075 -4.846749   \n",
       "3       15.0  ...  0.274293  0.110300  0.121964  0.033395  0.000000 -4.509599   \n",
       "4        5.0  ...  0.228036  0.073205  0.091880  0.078819  0.121534 -1.896240   \n",
       "\n",
       "       v_11      v_12      v_13      v_14  \n",
       "0  2.804097 -2.420821  0.795292  0.914762  \n",
       "1  2.096338 -1.030483 -1.722674  0.245522  \n",
       "2  1.803559  1.565330 -0.832687 -0.229963  \n",
       "3  1.285940 -0.501868 -2.438353 -0.478699  \n",
       "4  0.910783  0.931110  2.834518  1.923482  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   SaleID             150000 non-null  int64  \n",
      " 1   name               150000 non-null  int64  \n",
      " 2   regDate            150000 non-null  int64  \n",
      " 3   model              149999 non-null  float64\n",
      " 4   brand              150000 non-null  int64  \n",
      " 5   bodyType           145494 non-null  float64\n",
      " 6   fuelType           141320 non-null  float64\n",
      " 7   gearbox            144019 non-null  float64\n",
      " 8   power              150000 non-null  int64  \n",
      " 9   kilometer          150000 non-null  float64\n",
      " 10  notRepairedDamage  150000 non-null  object \n",
      " 11  regionCode         150000 non-null  int64  \n",
      " 12  seller             150000 non-null  int64  \n",
      " 13  offerType          150000 non-null  int64  \n",
      " 14  creatDate          150000 non-null  int64  \n",
      " 15  price              150000 non-null  int64  \n",
      " 16  v_0                150000 non-null  float64\n",
      " 17  v_1                150000 non-null  float64\n",
      " 18  v_2                150000 non-null  float64\n",
      " 19  v_3                150000 non-null  float64\n",
      " 20  v_4                150000 non-null  float64\n",
      " 21  v_5                150000 non-null  float64\n",
      " 22  v_6                150000 non-null  float64\n",
      " 23  v_7                150000 non-null  float64\n",
      " 24  v_8                150000 non-null  float64\n",
      " 25  v_9                150000 non-null  float64\n",
      " 26  v_10               150000 non-null  float64\n",
      " 27  v_11               150000 non-null  float64\n",
      " 28  v_12               150000 non-null  float64\n",
      " 29  v_13               150000 non-null  float64\n",
      " 30  v_14               150000 non-null  float64\n",
      "dtypes: float64(20), int64(10), object(1)\n",
      "memory usage: 35.5+ MB\n"
     ]
    }
   ],
   "source": [
    "Train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>149999.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>145494.000000</td>\n",
       "      <td>141320.000000</td>\n",
       "      <td>144019.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>74999.500000</td>\n",
       "      <td>68349.172873</td>\n",
       "      <td>2.003417e+07</td>\n",
       "      <td>47.129021</td>\n",
       "      <td>8.052733</td>\n",
       "      <td>1.792369</td>\n",
       "      <td>0.375842</td>\n",
       "      <td>0.224943</td>\n",
       "      <td>119.316547</td>\n",
       "      <td>12.597160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248204</td>\n",
       "      <td>0.044923</td>\n",
       "      <td>0.124692</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.061996</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>-0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43301.414527</td>\n",
       "      <td>61103.875095</td>\n",
       "      <td>5.364988e+04</td>\n",
       "      <td>49.536040</td>\n",
       "      <td>7.864956</td>\n",
       "      <td>1.760640</td>\n",
       "      <td>0.548677</td>\n",
       "      <td>0.417546</td>\n",
       "      <td>177.168419</td>\n",
       "      <td>3.919576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045804</td>\n",
       "      <td>0.051743</td>\n",
       "      <td>0.201410</td>\n",
       "      <td>0.029186</td>\n",
       "      <td>0.035692</td>\n",
       "      <td>3.772386</td>\n",
       "      <td>3.286071</td>\n",
       "      <td>2.517478</td>\n",
       "      <td>1.288988</td>\n",
       "      <td>1.038685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.991000e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.168192</td>\n",
       "      <td>-5.558207</td>\n",
       "      <td>-9.639552</td>\n",
       "      <td>-4.153899</td>\n",
       "      <td>-6.546556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37499.750000</td>\n",
       "      <td>11156.000000</td>\n",
       "      <td>1.999091e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243615</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.062474</td>\n",
       "      <td>0.035334</td>\n",
       "      <td>0.033930</td>\n",
       "      <td>-3.722303</td>\n",
       "      <td>-1.951543</td>\n",
       "      <td>-1.871846</td>\n",
       "      <td>-1.057789</td>\n",
       "      <td>-0.437034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74999.500000</td>\n",
       "      <td>51638.000000</td>\n",
       "      <td>2.003091e+07</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257798</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.095866</td>\n",
       "      <td>0.057014</td>\n",
       "      <td>0.058484</td>\n",
       "      <td>1.624076</td>\n",
       "      <td>-0.358053</td>\n",
       "      <td>-0.130753</td>\n",
       "      <td>-0.036245</td>\n",
       "      <td>0.141246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112499.250000</td>\n",
       "      <td>118841.250000</td>\n",
       "      <td>2.007111e+07</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265297</td>\n",
       "      <td>0.102009</td>\n",
       "      <td>0.125243</td>\n",
       "      <td>0.079382</td>\n",
       "      <td>0.087491</td>\n",
       "      <td>2.844357</td>\n",
       "      <td>1.255022</td>\n",
       "      <td>1.776933</td>\n",
       "      <td>0.942813</td>\n",
       "      <td>0.680378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>149999.000000</td>\n",
       "      <td>196812.000000</td>\n",
       "      <td>2.015121e+07</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19312.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291838</td>\n",
       "      <td>0.151420</td>\n",
       "      <td>1.404936</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>0.222787</td>\n",
       "      <td>12.357011</td>\n",
       "      <td>18.819042</td>\n",
       "      <td>13.847792</td>\n",
       "      <td>11.147669</td>\n",
       "      <td>8.658418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SaleID           name       regDate          model  \\\n",
       "count  150000.000000  150000.000000  1.500000e+05  149999.000000   \n",
       "mean    74999.500000   68349.172873  2.003417e+07      47.129021   \n",
       "std     43301.414527   61103.875095  5.364988e+04      49.536040   \n",
       "min         0.000000       0.000000  1.991000e+07       0.000000   \n",
       "25%     37499.750000   11156.000000  1.999091e+07      10.000000   \n",
       "50%     74999.500000   51638.000000  2.003091e+07      30.000000   \n",
       "75%    112499.250000  118841.250000  2.007111e+07      66.000000   \n",
       "max    149999.000000  196812.000000  2.015121e+07     247.000000   \n",
       "\n",
       "               brand       bodyType       fuelType        gearbox  \\\n",
       "count  150000.000000  145494.000000  141320.000000  144019.000000   \n",
       "mean        8.052733       1.792369       0.375842       0.224943   \n",
       "std         7.864956       1.760640       0.548677       0.417546   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         6.000000       1.000000       0.000000       0.000000   \n",
       "75%        13.000000       3.000000       1.000000       0.000000   \n",
       "max        39.000000       7.000000       6.000000       1.000000   \n",
       "\n",
       "               power      kilometer  ...            v_5            v_6  \\\n",
       "count  150000.000000  150000.000000  ...  150000.000000  150000.000000   \n",
       "mean      119.316547      12.597160  ...       0.248204       0.044923   \n",
       "std       177.168419       3.919576  ...       0.045804       0.051743   \n",
       "min         0.000000       0.500000  ...       0.000000       0.000000   \n",
       "25%        75.000000      12.500000  ...       0.243615       0.000038   \n",
       "50%       110.000000      15.000000  ...       0.257798       0.000812   \n",
       "75%       150.000000      15.000000  ...       0.265297       0.102009   \n",
       "max     19312.000000      15.000000  ...       0.291838       0.151420   \n",
       "\n",
       "                 v_7            v_8            v_9           v_10  \\\n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean        0.124692       0.058144       0.061996      -0.001000   \n",
       "std         0.201410       0.029186       0.035692       3.772386   \n",
       "min         0.000000       0.000000       0.000000      -9.168192   \n",
       "25%         0.062474       0.035334       0.033930      -3.722303   \n",
       "50%         0.095866       0.057014       0.058484       1.624076   \n",
       "75%         0.125243       0.079382       0.087491       2.844357   \n",
       "max         1.404936       0.160791       0.222787      12.357011   \n",
       "\n",
       "                v_11           v_12           v_13           v_14  \n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000  \n",
       "mean        0.009035       0.004813       0.000313      -0.000688  \n",
       "std         3.286071       2.517478       1.288988       1.038685  \n",
       "min        -5.558207      -9.639552      -4.153899      -6.546556  \n",
       "25%        -1.951543      -1.871846      -1.057789      -0.437034  \n",
       "50%        -0.358053      -0.130753      -0.036245       0.141246  \n",
       "75%         1.255022       1.776933       0.942813       0.680378  \n",
       "max        18.819042      13.847792      11.147669       8.658418  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SaleID',\n",
       " 'name',\n",
       " 'regDate',\n",
       " 'model',\n",
       " 'brand',\n",
       " 'bodyType',\n",
       " 'fuelType',\n",
       " 'gearbox',\n",
       " 'power',\n",
       " 'kilometer',\n",
       " 'notRepairedDamage',\n",
       " 'regionCode',\n",
       " 'seller',\n",
       " 'offerType',\n",
       " 'creatDate',\n",
       " 'price',\n",
       " 'v_0',\n",
       " 'v_1',\n",
       " 'v_2',\n",
       " 'v_3',\n",
       " 'v_4',\n",
       " 'v_5',\n",
       " 'v_6',\n",
       " 'v_7',\n",
       " 'v_8',\n",
       " 'v_9',\n",
       " 'v_10',\n",
       " 'v_11',\n",
       " 'v_12',\n",
       " 'v_13',\n",
       " 'v_14']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(Train_data.columns)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别特征\n",
    "cate_cols = ['SaleID', 'name', 'model', 'brand', 'bodyType', \n",
    "             'fuelType','gearbox', 'power', 'notRepairedDamage', \n",
    "             'regionCode','seller', 'offerType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regDate',\n",
       " 'kilometer',\n",
       " 'creatDate',\n",
       " 'price',\n",
       " 'v_0',\n",
       " 'v_1',\n",
       " 'v_2',\n",
       " 'v_3',\n",
       " 'v_4',\n",
       " 'v_5',\n",
       " 'v_6',\n",
       " 'v_7',\n",
       " 'v_8',\n",
       " 'v_9',\n",
       " 'v_10',\n",
       " 'v_11',\n",
       " 'v_12',\n",
       " 'v_13',\n",
       " 'v_14']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数值特征\n",
    "num_cols = [x for x in cols if x not in cate_cols]\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaleID has 150000 unique values\n",
      "0        1\n",
      "23262    1\n",
      "56014    1\n",
      "53967    1\n",
      "10960    1\n",
      "        ..\n",
      "1322     1\n",
      "3371     1\n",
      "13612    1\n",
      "15661    1\n",
      "2047     1\n",
      "Name: SaleID, Length: 150000, dtype: int64\n",
      "name has 99662 unique values\n",
      "387       282\n",
      "708       282\n",
      "55        280\n",
      "1541      263\n",
      "203       233\n",
      "         ... \n",
      "26403       1\n",
      "28450       1\n",
      "32544       1\n",
      "102174      1\n",
      "184730      1\n",
      "Name: name, Length: 99662, dtype: int64\n",
      "model has 248 unique values\n",
      "0.0      11762\n",
      "19.0      9573\n",
      "4.0       8445\n",
      "1.0       6038\n",
      "29.0      5186\n",
      "         ...  \n",
      "242.0        2\n",
      "209.0        2\n",
      "245.0        2\n",
      "240.0        2\n",
      "247.0        1\n",
      "Name: model, Length: 248, dtype: int64\n",
      "brand has 40 unique values\n",
      "0     31480\n",
      "4     16737\n",
      "14    16089\n",
      "10    14249\n",
      "1     13794\n",
      "6     10217\n",
      "9      7306\n",
      "5      4665\n",
      "13     3817\n",
      "11     2945\n",
      "3      2461\n",
      "7      2361\n",
      "16     2223\n",
      "8      2077\n",
      "25     2064\n",
      "27     2053\n",
      "21     1547\n",
      "15     1458\n",
      "19     1388\n",
      "20     1236\n",
      "12     1109\n",
      "22     1085\n",
      "26      966\n",
      "30      940\n",
      "17      913\n",
      "24      772\n",
      "28      649\n",
      "32      592\n",
      "29      406\n",
      "37      333\n",
      "2       321\n",
      "31      318\n",
      "18      316\n",
      "36      228\n",
      "34      227\n",
      "33      218\n",
      "23      186\n",
      "35      180\n",
      "38       65\n",
      "39        9\n",
      "Name: brand, dtype: int64\n",
      "bodyType has 8 unique values\n",
      "0.0    41420\n",
      "1.0    35272\n",
      "2.0    30324\n",
      "3.0    13491\n",
      "4.0     9609\n",
      "5.0     7607\n",
      "6.0     6482\n",
      "7.0     1289\n",
      "Name: bodyType, dtype: int64\n",
      "fuelType has 7 unique values\n",
      "0.0    91656\n",
      "1.0    46991\n",
      "2.0     2212\n",
      "3.0      262\n",
      "4.0      118\n",
      "5.0       45\n",
      "6.0       36\n",
      "Name: fuelType, dtype: int64\n",
      "gearbox has 2 unique values\n",
      "0.0    111623\n",
      "1.0     32396\n",
      "Name: gearbox, dtype: int64\n",
      "power has 566 unique values\n",
      "0       12829\n",
      "75       9593\n",
      "150      6495\n",
      "60       6374\n",
      "140      5963\n",
      "        ...  \n",
      "1993        1\n",
      "202         1\n",
      "587         1\n",
      "332         1\n",
      "3454        1\n",
      "Name: power, Length: 566, dtype: int64\n",
      "notRepairedDamage has 3 unique values\n",
      "0.0    111361\n",
      "-       24324\n",
      "1.0     14315\n",
      "Name: notRepairedDamage, dtype: int64\n",
      "regionCode has 7905 unique values\n",
      "419     369\n",
      "764     258\n",
      "125     137\n",
      "176     136\n",
      "462     134\n",
      "       ... \n",
      "7081      1\n",
      "7243      1\n",
      "7319      1\n",
      "7742      1\n",
      "7960      1\n",
      "Name: regionCode, Length: 7905, dtype: int64\n",
      "seller has 2 unique values\n",
      "0    149999\n",
      "1         1\n",
      "Name: seller, dtype: int64\n",
      "offerType has 1 unique values\n",
      "0    150000\n",
      "Name: offerType, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 类别特征分析\n",
    "for col in cate_cols:\n",
    "    print(\"{} has {} unique values\".format(col, Train_data[col].nunique()))\n",
    "    print(Train_data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regDate</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>creatDate</th>\n",
       "      <th>price</th>\n",
       "      <th>v_0</th>\n",
       "      <th>v_1</th>\n",
       "      <th>v_2</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_4</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.003417e+07</td>\n",
       "      <td>12.597160</td>\n",
       "      <td>2.016033e+07</td>\n",
       "      <td>5923.327333</td>\n",
       "      <td>44.406268</td>\n",
       "      <td>-0.044809</td>\n",
       "      <td>0.080765</td>\n",
       "      <td>0.078833</td>\n",
       "      <td>0.017875</td>\n",
       "      <td>0.248204</td>\n",
       "      <td>0.044923</td>\n",
       "      <td>0.124692</td>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.061996</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>-0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.364988e+04</td>\n",
       "      <td>3.919576</td>\n",
       "      <td>1.067328e+02</td>\n",
       "      <td>7501.998477</td>\n",
       "      <td>2.457548</td>\n",
       "      <td>3.641893</td>\n",
       "      <td>2.929618</td>\n",
       "      <td>2.026514</td>\n",
       "      <td>1.193661</td>\n",
       "      <td>0.045804</td>\n",
       "      <td>0.051743</td>\n",
       "      <td>0.201410</td>\n",
       "      <td>0.029186</td>\n",
       "      <td>0.035692</td>\n",
       "      <td>3.772386</td>\n",
       "      <td>3.286071</td>\n",
       "      <td>2.517478</td>\n",
       "      <td>1.288988</td>\n",
       "      <td>1.038685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.991000e+07</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.015062e+07</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>30.451976</td>\n",
       "      <td>-4.295589</td>\n",
       "      <td>-4.470671</td>\n",
       "      <td>-7.275037</td>\n",
       "      <td>-4.364565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.168192</td>\n",
       "      <td>-5.558207</td>\n",
       "      <td>-9.639552</td>\n",
       "      <td>-4.153899</td>\n",
       "      <td>-6.546556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.999091e+07</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>2.016031e+07</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>43.135799</td>\n",
       "      <td>-3.192349</td>\n",
       "      <td>-0.970671</td>\n",
       "      <td>-1.462580</td>\n",
       "      <td>-0.921191</td>\n",
       "      <td>0.243615</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.062474</td>\n",
       "      <td>0.035334</td>\n",
       "      <td>0.033930</td>\n",
       "      <td>-3.722303</td>\n",
       "      <td>-1.951543</td>\n",
       "      <td>-1.871846</td>\n",
       "      <td>-1.057789</td>\n",
       "      <td>-0.437034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.003091e+07</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.016032e+07</td>\n",
       "      <td>3250.000000</td>\n",
       "      <td>44.610266</td>\n",
       "      <td>-3.052671</td>\n",
       "      <td>-0.382947</td>\n",
       "      <td>0.099722</td>\n",
       "      <td>-0.075910</td>\n",
       "      <td>0.257798</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.095866</td>\n",
       "      <td>0.057014</td>\n",
       "      <td>0.058484</td>\n",
       "      <td>1.624076</td>\n",
       "      <td>-0.358053</td>\n",
       "      <td>-0.130753</td>\n",
       "      <td>-0.036245</td>\n",
       "      <td>0.141246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.007111e+07</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.016033e+07</td>\n",
       "      <td>7700.000000</td>\n",
       "      <td>46.004721</td>\n",
       "      <td>4.000670</td>\n",
       "      <td>0.241335</td>\n",
       "      <td>1.565838</td>\n",
       "      <td>0.868758</td>\n",
       "      <td>0.265297</td>\n",
       "      <td>0.102009</td>\n",
       "      <td>0.125243</td>\n",
       "      <td>0.079382</td>\n",
       "      <td>0.087491</td>\n",
       "      <td>2.844357</td>\n",
       "      <td>1.255022</td>\n",
       "      <td>1.776933</td>\n",
       "      <td>0.942813</td>\n",
       "      <td>0.680378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.015121e+07</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>52.304178</td>\n",
       "      <td>7.320308</td>\n",
       "      <td>19.035496</td>\n",
       "      <td>9.854702</td>\n",
       "      <td>6.829352</td>\n",
       "      <td>0.291838</td>\n",
       "      <td>0.151420</td>\n",
       "      <td>1.404936</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>0.222787</td>\n",
       "      <td>12.357011</td>\n",
       "      <td>18.819042</td>\n",
       "      <td>13.847792</td>\n",
       "      <td>11.147669</td>\n",
       "      <td>8.658418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            regDate      kilometer     creatDate          price  \\\n",
       "count  1.500000e+05  150000.000000  1.500000e+05  150000.000000   \n",
       "mean   2.003417e+07      12.597160  2.016033e+07    5923.327333   \n",
       "std    5.364988e+04       3.919576  1.067328e+02    7501.998477   \n",
       "min    1.991000e+07       0.500000  2.015062e+07      11.000000   \n",
       "25%    1.999091e+07      12.500000  2.016031e+07    1300.000000   \n",
       "50%    2.003091e+07      15.000000  2.016032e+07    3250.000000   \n",
       "75%    2.007111e+07      15.000000  2.016033e+07    7700.000000   \n",
       "max    2.015121e+07      15.000000  2.016041e+07   99999.000000   \n",
       "\n",
       "                 v_0            v_1            v_2            v_3  \\\n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean       44.406268      -0.044809       0.080765       0.078833   \n",
       "std         2.457548       3.641893       2.929618       2.026514   \n",
       "min        30.451976      -4.295589      -4.470671      -7.275037   \n",
       "25%        43.135799      -3.192349      -0.970671      -1.462580   \n",
       "50%        44.610266      -3.052671      -0.382947       0.099722   \n",
       "75%        46.004721       4.000670       0.241335       1.565838   \n",
       "max        52.304178       7.320308      19.035496       9.854702   \n",
       "\n",
       "                 v_4            v_5            v_6            v_7  \\\n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean        0.017875       0.248204       0.044923       0.124692   \n",
       "std         1.193661       0.045804       0.051743       0.201410   \n",
       "min        -4.364565       0.000000       0.000000       0.000000   \n",
       "25%        -0.921191       0.243615       0.000038       0.062474   \n",
       "50%        -0.075910       0.257798       0.000812       0.095866   \n",
       "75%         0.868758       0.265297       0.102009       0.125243   \n",
       "max         6.829352       0.291838       0.151420       1.404936   \n",
       "\n",
       "                 v_8            v_9           v_10           v_11  \\\n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean        0.058144       0.061996      -0.001000       0.009035   \n",
       "std         0.029186       0.035692       3.772386       3.286071   \n",
       "min         0.000000       0.000000      -9.168192      -5.558207   \n",
       "25%         0.035334       0.033930      -3.722303      -1.951543   \n",
       "50%         0.057014       0.058484       1.624076      -0.358053   \n",
       "75%         0.079382       0.087491       2.844357       1.255022   \n",
       "max         0.160791       0.222787      12.357011      18.819042   \n",
       "\n",
       "                v_12           v_13           v_14  \n",
       "count  150000.000000  150000.000000  150000.000000  \n",
       "mean        0.004813       0.000313      -0.000688  \n",
       "std         2.517478       1.288988       1.038685  \n",
       "min        -9.639552      -4.153899      -6.546556  \n",
       "25%        -1.871846      -1.057789      -0.437034  \n",
       "50%        -0.130753      -0.036245       0.141246  \n",
       "75%         1.776933       0.942813       0.680378  \n",
       "max        13.847792      11.147669       8.658418  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数值特征分析\n",
    "num_df = Train_data[num_cols]\n",
    "num_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price        1.000000\n",
      "v_12         0.692823\n",
      "v_8          0.685798\n",
      "v_0          0.628397\n",
      "regDate      0.611959\n",
      "v_5          0.164317\n",
      "v_2          0.085322\n",
      "v_6          0.068970\n",
      "v_1          0.060914\n",
      "v_14         0.035911\n",
      "creatDate    0.002955\n",
      "v_13        -0.013993\n",
      "v_7         -0.053024\n",
      "v_4         -0.147085\n",
      "v_9         -0.206205\n",
      "v_10        -0.246175\n",
      "v_11        -0.275320\n",
      "kilometer   -0.440519\n",
      "v_3         -0.730946\n",
      "Name: price, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 相关性分析\n",
    "target_numeric = Train_data[num_cols]\n",
    "correlation = target_numeric.corr()\n",
    "print(correlation['price'].sort_values(ascending=False), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price    1.000000\n",
      "v_12     0.692823\n",
      "v_8      0.685798\n",
      "v_0      0.628397\n",
      "Name: price, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 选择特征字段中与标签强相关的3个字段，绘制其余标签的分布关系图\n",
    "tmp_cols = ['price', 'v_12', 'v_8', 'v_0']\n",
    "tmp_target_numeric = Train_data[tmp_cols]\n",
    "tmp_correlation = tmp_target_numeric.corr()\n",
    "print(tmp_correlation['price'].sort_values(ascending=False), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Correlation of Numeric Features with Price'}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f , ax = plt.subplots(figsize = (7, 7))\n",
    "\n",
    "plt.title('Correlation of Numeric Features with Price',y=1,size=16)\n",
    "\n",
    "sns.heatmap(tmp_correlation, square = True,  vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务3：对标签进行数据分析，并使用 log 进行转换\n",
    "* 使用Pandas对标签字段进行数据分析\n",
    "* 使用 log 对标签字段进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.DataFrame()\n",
    "target_df['price'] = Train_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 查看预测值的具体频数\n",
    "plt.hist(target_df['price'], orientation = 'vertical',histtype = 'bar', color ='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    150000.000000\n",
       "mean       5923.327333\n",
       "std        7501.998477\n",
       "min          11.000000\n",
       "25%        1300.000000\n",
       "50%        3250.000000\n",
       "75%        7700.000000\n",
       "max       99999.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 有无缺失值\n",
    "target_df['price'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log+1变换\n",
    "target_df['price_log'] = np.log(target_df['price']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850</td>\n",
       "      <td>7.523481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3600</td>\n",
       "      <td>8.188967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6222</td>\n",
       "      <td>8.736007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2400</td>\n",
       "      <td>7.783641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5200</td>\n",
       "      <td>8.556606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>5900</td>\n",
       "      <td>8.682877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>9500</td>\n",
       "      <td>9.159152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>7500</td>\n",
       "      <td>8.922792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>4999</td>\n",
       "      <td>8.517193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>4700</td>\n",
       "      <td>8.455531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  price_log\n",
       "0        1850   7.523481\n",
       "1        3600   8.188967\n",
       "2        6222   8.736007\n",
       "3        2400   7.783641\n",
       "4        5200   8.556606\n",
       "...       ...        ...\n",
       "149995   5900   8.682877\n",
       "149996   9500   9.159152\n",
       "149997   7500   8.922792\n",
       "149998   4999   8.517193\n",
       "149999   4700   8.455531\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df['h'] = np.power(np.e, target_df['price_log'])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_log</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850</td>\n",
       "      <td>7.523481</td>\n",
       "      <td>1850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3600</td>\n",
       "      <td>8.188967</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6222</td>\n",
       "      <td>8.736007</td>\n",
       "      <td>6222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2400</td>\n",
       "      <td>7.783641</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5200</td>\n",
       "      <td>8.556606</td>\n",
       "      <td>5200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>5900</td>\n",
       "      <td>8.682877</td>\n",
       "      <td>5900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>9500</td>\n",
       "      <td>9.159152</td>\n",
       "      <td>9500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>7500</td>\n",
       "      <td>8.922792</td>\n",
       "      <td>7500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>4999</td>\n",
       "      <td>8.517193</td>\n",
       "      <td>4999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>4700</td>\n",
       "      <td>8.455531</td>\n",
       "      <td>4700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  price_log       h\n",
       "0        1850   7.523481  1850.0\n",
       "1        3600   8.188967  3600.0\n",
       "2        6222   8.736007  6222.0\n",
       "3        2400   7.783641  2400.0\n",
       "4        5200   8.556606  5200.0\n",
       "...       ...        ...     ...\n",
       "149995   5900   8.682877  5900.0\n",
       "149996   9500   9.159152  9500.0\n",
       "149997   7500   8.922792  7500.0\n",
       "149998   4999   8.517193  4999.0\n",
       "149999   4700   8.455531  4700.0\n",
       "\n",
       "[150000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(target_df['price_log'], orientation = 'vertical',histtype = 'bar', color ='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df['SaleID'] = Train_data[['SaleID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'price_log', 'h', 'SaleID'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Train_data['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务4：使用特征工程对比赛字段进行编码\n",
    "* 对数据集中类别字段（取值空间大于2）的进行字段进行onehot操作\n",
    "* 对日期特征提取年月日等信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 31)\n"
     ]
    }
   ],
   "source": [
    "# 合并训练集与测试集字段构造特征\n",
    "Train_data['train'] = 1\n",
    "Test_data['train'] = 0\n",
    "data = pd.concat([Train_data, Test_data], axis=0, ignore_index=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',\n",
       "       'gearbox', 'power', 'kilometer', 'notRepairedDamage', 'regionCode',\n",
       "       'seller', 'offerType', 'creatDate', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4',\n",
       "       'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13',\n",
       "       'v_14', 'train'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1 \n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_cols = ['model','brand','bodyType','fuelType','notRepairedDamage']\n",
    "enc = OneHotEncoder(handle_unknown='ignore', dtype=int)\n",
    "enc.fit(data[oh_cols])\n",
    "oh_df = pd.DataFrame(enc.transform(data[oh_cols]).toarray(), columns=enc.get_feature_names(), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 309)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 335)\n"
     ]
    }
   ],
   "source": [
    "data1 = data.drop(oh_cols, axis=1)\n",
    "data1 = pd.concat([data1, oh_df], axis=1)\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 332)\n",
      "Index(['SaleID', 'name', 'regDate', 'gearbox', 'power', 'kilometer',\n",
      "       'regionCode', 'seller', 'offerType', 'creatDate',\n",
      "       ...\n",
      "       'fuelType_0.0', 'fuelType_1.0', 'fuelType_2.0', 'fuelType_3.0',\n",
      "       'fuelType_4.0', 'fuelType_5.0', 'fuelType_6.0', 'notRepairedDamage_-',\n",
      "       'notRepairedDamage_0.0', 'notRepairedDamage_1.0'],\n",
      "      dtype='object', length=332)\n"
     ]
    }
   ],
   "source": [
    "# method 2\n",
    "data2 = pd.get_dummies(data, columns=oh_cols)\n",
    "print(data2.shape)\n",
    "print(data2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 方法一和方法二的差别在于OneHotEncoder对nan数据也进行了编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间特征处理\n",
    "data1['regDate'] = pd.to_datetime(data1['regDate'], errors='coerce', format='%Y%m%d')\n",
    "data1['creatDate'] = pd.to_datetime(data1['creatDate'], errors='coerce', format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['creatDate_daysinmon'] = data1['creatDate'].dt.daysinmonth\n",
    "data1['creatDate_dayofweek'] = data1['creatDate'].dt.dayofweek\n",
    "data1['creatDate_dayofyear'] = data1['creatDate'].dt.dayofyear\n",
    "data1['creatDate_weekofyear'] = data1['creatDate'].dt.weekofyear\n",
    "data1['creatDate_monstart_end'] = (data1['creatDate'].dt.is_month_start|data1['creatDate'].dt.is_month_end).replace({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['regDate_daysinmon'] = data1['regDate'].dt.daysinmonth\n",
    "data1['regDate_dayofweek'] = data1['regDate'].dt.dayofweek\n",
    "data1['regDate_dayofyear'] = data1['regDate'].dt.dayofyear\n",
    "data1['regDate_weekofyear'] = data1['regDate'].dt.weekofyear\n",
    "data1['regDate_monstart_end'] = (data1['regDate'].dt.is_month_start|data1['regDate'].dt.is_month_end).replace({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['creatDate_regDate_diff'] = (data1['creatDate'] - data1['regDate']).fillna(pd.Timedelta(seconds=0)).dt.days.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data1['regDate']\n",
    "del data1['creatDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 344)\n"
     ]
    }
   ],
   "source": [
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'gearbox', 'power', 'kilometer', 'regionCode',\n",
       "       'seller', 'offerType', 'v_0', 'v_1',\n",
       "       ...\n",
       "       'creatDate_dayofweek', 'creatDate_dayofyear', 'creatDate_weekofyear',\n",
       "       'creatDate_monstart_end', 'regDate_daysinmon', 'regDate_dayofweek',\n",
       "       'regDate_dayofyear', 'regDate_weekofyear', 'regDate_monstart_end',\n",
       "       'creatDate_regDate_diff'],\n",
       "      dtype='object', length=344)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务5：使用 Sklearn 中基础树模型完成训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 五折交叉验证的数据划分方法（KFold）\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(data1[data1['train']==1], target_df, on='SaleID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 343)\n"
     ]
    }
   ],
   "source": [
    "train_x = train[data1.columns].drop('SaleID', axis=1)\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 343)\n"
     ]
    }
   ],
   "source": [
    "test = data1[data1['train']==0].drop('SaleID', axis=1)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用sklearn中随机森林模型\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 train score:0.05893001523097096\n",
      "1 val score:0.14556054097631357\n",
      "2 train score:0.058739897922304316\n",
      "2 val score:0.14552089475273952\n",
      "3 train score:0.05860049685596526\n",
      "3 val score:0.14691564992880107\n",
      "4 train score:0.05886320112970154\n",
      "4 val score:0.14422757585115567\n",
      "5 train score:0.0585562679722614\n",
      "5 val score:0.1463497863431485\n",
      "Train mae: 0.0585562679722614\n",
      "val mae: 0.14571488957043166\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cnt = 0\n",
    "scores = []\n",
    "scores_train = []\n",
    "pred_test = []\n",
    "regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=2021)\n",
    "\n",
    "train_y = train['price_log']\n",
    "\n",
    "for train_index, val_index in kf.split(train_x):\n",
    "    cnt += 1  \n",
    "    X_train, X_val = train_x.iloc[train_index].values, train_x.iloc[val_index].values  \n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "#     print(\"X_train shape: \", X_train.shape)\n",
    "#     print(\"X_val shape:\", y_train.shape)\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred_train = regr.predict(X_train)\n",
    "    pred_val = regr.predict(X_val)\n",
    "    \n",
    "    pred_test.append(regr.predict(test).reshape(-1,).tolist())\n",
    "  \n",
    "    score_train = mean_absolute_error(y_train, pred_train)\n",
    "    print(\"{} train score:{}\".format(cnt, score_train))\n",
    "    scores_train.append(score_train)\n",
    "    \n",
    "    score_val = mean_absolute_error(y_val, pred_val)\n",
    "    print(\"{} val score:{}\".format(cnt, score_val))\n",
    "    scores.append(score_val)\n",
    "    \n",
    "print('Train mae:', np.mean(score_train))\n",
    "print('val mae:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对标签price按照大小划分成10等分，然后使用StratifiedKFold进行划分\n",
    "train['price_bin'] = pd.cut(train['price'], 10,labels=False)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, val_index in skf.split(train_x, train['price_bin']):    \n",
    "    X_train, X_val = train_x.iloc[train_index].values, train_x.iloc[val_index].values     \n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务6：成功将树模型的预测结果文件提交到天池\n",
    "* 使用StratifiedKFold配合随机森林完成模型的训练和预测\n",
    "* 在每折记录下模型对验证集和测试集的预测结果\n",
    "* 将多折测试集结果进行求均值，并写入csv提交到天池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train score:273.8098483333334\n",
      "0 val score:678.8501833333333\n",
      "1 train score:274.1433641666667\n",
      "1 val score:676.5069611111112\n",
      "2 train score:275.01094166666667\n",
      "2 val score:666.6310594444445\n",
      "3 train score:276.2332008333334\n",
      "3 val score:671.10893\n",
      "4 train score:274.94583111111103\n",
      "4 val score:677.6106644444444\n",
      "Train mae: 274.94583111111103\n",
      "val mae: 674.1415596666667\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=2021)\n",
    "\n",
    "cnt = 0\n",
    "scores = []\n",
    "scores_train = []\n",
    "pred_test = []\n",
    "train_y = train['price']\n",
    "\n",
    "for train_index, val_index in skf.split(train_x, train_y):    \n",
    "    \n",
    "#     print(\"TRAIN:\", train_index, \"val:\", val_index)    \n",
    "    X_train, X_val = train_x.iloc[train_index].values, train_x.iloc[val_index].values     \n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "#     print(\"X_train shape: \", X_train.shape)\n",
    "#     print(\"X_val shape:\", X_val.shape)\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred_train = regr.predict(X_train)\n",
    "    pred_val = regr.predict(X_val)\n",
    "    pred_test.append(regr.predict(test.values).reshape(-1,).tolist())\n",
    "\n",
    "    score_train = mean_absolute_error(y_train, pred_train)\n",
    "    print(\"{} train score:{}\".format(cnt, score_train))\n",
    "    scores_train.append(score_train)\n",
    "    \n",
    "    score_val = mean_absolute_error(y_val, pred_val)\n",
    "    print(\"{} val score:{}\".format(cnt, score_val))\n",
    "    scores.append(score_val)\n",
    "    \n",
    "    cnt += 1\n",
    "    \n",
    "print('Train mae:', np.mean(score_train))\n",
    "print('val mae:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.round(np.mean(pred_test, axis=0),2)\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['SaleID'] = data1[data1['train']==0]['SaleID']\n",
    "sub_df['price'] = sub\n",
    "\n",
    "res_name = 'RF_submit_'+str(time.time())+\".csv\"\n",
    "sub_df.to_csv('./submit/'+res_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务7：使用 XGBoost 模型完成训练和预测\n",
    "* 学会XGBoost模型的基础使用\n",
    "* 学会XGBoost模型的基础参数理解\n",
    "* 学会XGBoost模型的保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRFRegressor(\n",
    "    n_estimators=120, \n",
    "    learning_rate=0.1,\n",
    "    gamma=0, \n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.9,\n",
    "    max_depth=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRFRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bytree=0.9, gamma=0, gpu_id=-1, importance_type='gain',\n",
       "               interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "               max_depth=7, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=120, n_jobs=8,\n",
       "               num_parallel_tree=120, objective='reg:squarederror',\n",
       "               random_state=0, reg_alpha=0, scale_pos_weight=1,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.fit(train_x.loc[:1000-1,].values, train['price_log'][:1000,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred = model_xgb.predict(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存和加载\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save name: ./model/xgb_model_1633507036.5179465.dat\n"
     ]
    }
   ],
   "source": [
    "model_save_nm = \"./model/\"+\"xgb_model_\"+str(time.time())+\".dat\"\n",
    "print(\"model save name:\", model_save_nm)\n",
    "pickle.dump(model_xgb, open(model_save_nm, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1854234 , 1.2403396 , 1.3298208 , 1.2297554 , 1.3171523 ,\n",
       "       1.3525314 , 1.2331194 , 1.1490816 , 1.2678937 , 1.0891201 ,\n",
       "       1.2493066 , 1.3130935 , 1.1877002 , 1.2724652 , 1.2806468 ,\n",
       "       1.2408042 , 1.3950853 , 1.2846724 , 1.110128  , 1.1731206 ,\n",
       "       1.1360351 , 1.2463812 , 1.0269262 , 1.1218877 , 1.3581873 ,\n",
       "       1.2566496 , 1.2456666 , 1.2390637 , 1.2893225 , 1.2446228 ,\n",
       "       1.2428685 , 1.4037493 , 1.1619996 , 1.4076667 , 1.4229563 ,\n",
       "       1.3182441 , 1.3039206 , 1.3290886 , 1.3504202 , 1.336564  ,\n",
       "       1.2370266 , 1.2869    , 1.1791553 , 1.2869706 , 1.1675361 ,\n",
       "       1.0999702 , 1.3734515 , 1.3019265 , 1.3511337 , 1.349859  ,\n",
       "       1.356772  , 1.0549341 , 1.3576586 , 1.0808276 , 1.1355546 ,\n",
       "       1.2332433 , 1.3550606 , 1.2743516 , 1.2426305 , 1.2437046 ,\n",
       "       1.379672  , 1.2383113 , 0.9578109 , 1.1961403 , 1.1623144 ,\n",
       "       1.2469127 , 1.1479902 , 1.3258451 , 0.99546695, 1.2176344 ,\n",
       "       1.0863208 , 1.1551079 , 1.1323296 , 1.2794783 , 1.4080068 ,\n",
       "       1.3386326 , 1.391933  , 1.4216291 , 1.169597  , 1.2758027 ,\n",
       "       1.2165624 , 1.0938408 , 1.3277096 , 1.337252  , 1.1356679 ,\n",
       "       1.2859035 , 1.1289021 , 1.4464562 , 1.2767    , 1.3468052 ,\n",
       "       1.3015052 , 1.246581  , 1.4010267 , 1.2419895 , 1.330256  ,\n",
       "       1.233462  , 1.3401858 , 1.2354943 , 1.248471  , 1.2567452 ,\n",
       "       1.234917  , 1.2415525 , 1.1562946 , 1.2266767 , 1.4032604 ,\n",
       "       1.4393716 , 1.238751  , 1.3064721 , 1.1662354 , 1.1798065 ,\n",
       "       1.4229679 , 1.2511328 , 1.0847366 , 1.1314359 , 1.097482  ,\n",
       "       1.2570463 , 1.3733891 , 1.422394  , 1.0030488 , 1.2396674 ,\n",
       "       1.1520392 , 1.3566867 , 1.155822  , 1.0813632 , 1.269185  ,\n",
       "       1.115914  , 1.3122528 , 1.397139  , 1.0564078 , 1.2188641 ,\n",
       "       1.2616843 , 1.1090778 , 1.2414565 , 1.3161824 , 1.2346326 ,\n",
       "       1.4366466 , 1.0870837 , 1.2528487 , 1.412092  , 1.0295577 ,\n",
       "       1.3453386 , 1.1640836 , 1.2293254 , 1.1706367 , 1.3931825 ,\n",
       "       1.2989352 , 1.1095573 , 1.1408032 , 1.1189523 , 1.2606791 ,\n",
       "       1.155285  , 1.253359  , 1.4193022 , 1.2328885 , 0.92328167,\n",
       "       1.3309306 , 1.4916152 , 1.2658744 , 1.2262322 , 1.305088  ,\n",
       "       1.2478225 , 1.260147  , 1.3269517 , 1.5508    , 1.1473509 ,\n",
       "       1.3585374 , 1.407694  , 1.2479074 , 1.1853242 , 1.1235565 ,\n",
       "       1.2457229 , 1.4146954 , 1.3162196 , 1.4499004 , 1.0882697 ,\n",
       "       1.1893986 , 1.2459931 , 1.2425144 , 1.3592448 , 1.125019  ,\n",
       "       1.3578213 , 1.3024331 , 1.3198172 , 1.308254  , 1.3292124 ,\n",
       "       1.0969468 , 1.1791583 , 1.4608952 , 1.2316165 , 1.1368593 ,\n",
       "       1.2366205 , 1.4055482 , 1.1495409 , 1.20963   , 1.1837336 ,\n",
       "       1.3373041 , 1.2335169 , 0.9636342 , 1.3909744 , 1.1025954 ,\n",
       "       1.4019928 , 1.2084031 , 1.1616983 , 1.217906  , 1.1745656 ,\n",
       "       1.3357137 , 1.4539294 , 1.1006548 , 1.3058093 , 1.3833913 ,\n",
       "       1.4032617 , 1.2064382 , 1.1026293 , 1.4061046 , 1.2169176 ,\n",
       "       1.3038203 , 1.1609544 , 1.211249  , 1.3216271 , 1.3757854 ,\n",
       "       1.2489963 , 1.4382603 , 1.2369608 , 1.1645887 , 1.0766929 ,\n",
       "       1.3075372 , 1.2665697 , 1.1080538 , 1.2897866 , 1.2746693 ,\n",
       "       1.4280277 , 1.1185131 , 1.0870123 , 1.4019276 , 1.304038  ,\n",
       "       1.4136235 , 1.3218632 , 1.3527241 , 1.1931251 , 1.2441233 ,\n",
       "       1.1313249 , 1.2510109 , 1.3197505 , 1.3906013 , 1.3638238 ,\n",
       "       1.2861509 , 1.1739001 , 1.2163923 , 1.2961221 , 1.3435248 ,\n",
       "       1.1669999 , 1.357542  , 1.1553515 , 1.2114943 , 1.2675849 ,\n",
       "       1.2316273 , 1.4138174 , 1.1528188 , 1.1424191 , 1.340688  ,\n",
       "       1.2396357 , 1.228171  , 1.0830836 , 1.3488258 , 1.0040278 ,\n",
       "       1.25259   , 1.1290731 , 1.3133426 , 1.0754334 , 1.1776295 ,\n",
       "       1.2500025 , 1.2381778 , 1.1653448 , 1.0184424 , 1.0576102 ,\n",
       "       1.3085804 , 1.2274288 , 1.4652282 , 1.2360941 , 1.2359197 ,\n",
       "       1.3216438 , 1.0873152 , 1.1261758 , 1.2154648 , 1.4752444 ,\n",
       "       1.2763557 , 1.2907995 , 1.2560493 , 1.3462906 , 1.1232339 ,\n",
       "       1.1027874 , 1.2423785 , 1.1793427 , 1.2530155 , 1.2289203 ,\n",
       "       1.332282  , 1.3169514 , 0.9901119 , 1.3923184 , 1.2052631 ,\n",
       "       1.4084322 , 1.4121288 , 1.3539474 , 1.2335664 , 1.3112223 ,\n",
       "       1.3145343 , 1.2816918 , 1.1308247 , 1.4266076 , 1.319551  ,\n",
       "       1.081146  , 1.2453641 , 1.1126595 , 1.3952581 , 1.2132555 ,\n",
       "       1.4455107 , 1.4750504 , 1.1957465 , 1.2953781 , 1.3763825 ,\n",
       "       1.1230079 , 1.1077285 , 1.2627335 , 1.1678766 , 1.292772  ,\n",
       "       1.3734927 , 1.2372892 , 1.226611  , 1.3131526 , 1.1610923 ,\n",
       "       1.3086241 , 1.0191439 , 1.4787595 , 1.3324183 , 1.1467657 ,\n",
       "       1.4781601 , 1.176594  , 1.1337578 , 1.2372478 , 1.2442542 ,\n",
       "       1.4086651 , 1.0851696 , 1.3426379 , 1.231343  , 1.3059419 ,\n",
       "       1.0662888 , 1.1353469 , 1.3196001 , 1.1323452 , 1.4544673 ,\n",
       "       1.1217335 , 1.2010716 , 1.3660278 , 1.1684679 , 1.2121229 ,\n",
       "       1.16439   , 1.1111671 , 1.2129661 , 1.2346551 , 1.2076097 ,\n",
       "       1.2321157 , 1.2609838 , 1.316481  , 1.2945969 , 1.3724074 ,\n",
       "       1.1584759 , 1.0963879 , 1.4213053 , 1.4216633 , 1.4088806 ,\n",
       "       1.3302586 , 1.3219652 , 1.2476671 , 1.5105119 , 1.3452806 ,\n",
       "       0.9946603 , 1.1371492 , 1.5814269 , 1.166039  , 1.4298563 ,\n",
       "       1.0877719 , 1.4689096 , 1.2431117 , 1.3455664 , 1.513163  ,\n",
       "       1.2271602 , 1.2861261 , 1.3823363 , 1.1848992 , 1.2479111 ,\n",
       "       1.3487318 , 1.329421  , 1.2851038 , 1.3188827 , 1.159864  ,\n",
       "       1.3001354 , 1.1335874 , 1.2481307 , 1.3933119 , 1.3409662 ,\n",
       "       1.3085272 , 1.302276  , 1.4120172 , 1.4168473 , 1.3390238 ,\n",
       "       1.1623389 , 1.4094235 , 1.1113825 , 1.3617762 , 1.1771445 ,\n",
       "       1.21453   , 1.4391884 , 1.1144066 , 1.3505961 , 1.2291491 ,\n",
       "       1.3037518 , 1.4057442 , 1.2334429 , 1.442955  , 1.1714064 ,\n",
       "       1.1095196 , 1.2782425 , 1.1734391 , 1.161667  , 1.1813457 ,\n",
       "       1.2391565 , 1.2681216 , 1.2949938 , 1.2389157 , 1.1227386 ,\n",
       "       1.112291  , 1.3356305 , 1.3575195 , 1.3421291 , 1.1947584 ,\n",
       "       1.5699688 , 1.3607239 , 1.1139535 , 1.3571886 , 1.4296532 ,\n",
       "       1.445135  , 1.3661215 , 1.3410443 , 1.1394091 , 1.1744579 ,\n",
       "       1.2957698 , 1.3116025 , 1.1296737 , 1.3823363 , 1.0877116 ,\n",
       "       1.2467574 , 1.2492636 , 1.2071772 , 1.4290904 , 1.3015006 ,\n",
       "       1.2062682 , 1.3168527 , 1.2746414 , 1.1468983 , 1.3326001 ,\n",
       "       1.4016509 , 1.182073  , 1.0279235 , 1.4066386 , 1.2337545 ,\n",
       "       1.3214927 , 1.4031827 , 1.1949897 , 1.0549629 , 1.2022959 ,\n",
       "       1.2455771 , 1.010024  , 1.2233441 , 1.2339646 , 1.317968  ,\n",
       "       1.1273574 , 1.3848302 , 1.3876052 , 1.2189394 , 1.4640068 ,\n",
       "       1.0125577 , 1.3995944 , 1.2849802 , 1.2370229 , 1.3783762 ,\n",
       "       1.1818374 , 1.2047081 , 0.86320406, 1.2193925 , 1.4138218 ,\n",
       "       1.2853436 , 1.1750085 , 1.3039954 , 1.2267548 , 1.142799  ,\n",
       "       1.0119005 , 1.2490053 , 1.352081  , 1.3445439 , 1.1333224 ,\n",
       "       1.4287704 , 1.2370473 , 1.0947776 , 1.0242459 , 1.3216307 ,\n",
       "       1.2997683 , 1.0274314 , 1.0240674 , 1.3114915 , 1.4084907 ,\n",
       "       1.4111536 , 1.3139297 , 1.4499799 , 1.4137886 , 1.2216644 ,\n",
       "       1.1896151 , 1.3117232 , 1.3178465 , 1.4059902 , 1.2745261 ,\n",
       "       1.1084747 , 1.478346  , 1.0585984 , 1.1400055 , 1.2350154 ,\n",
       "       1.1287585 , 1.1741749 , 1.2967173 , 1.2127805 , 1.1745235 ,\n",
       "       1.2958667 , 1.4152172 , 1.2714697 , 1.1865859 , 1.1704999 ,\n",
       "       1.2320331 , 1.3662425 , 1.3609169 , 1.3031054 , 1.3283997 ,\n",
       "       1.2096499 , 1.2594013 , 1.3505121 , 1.305397  , 1.2398477 ,\n",
       "       1.4056896 , 1.4017755 , 1.3373203 , 1.3770453 , 1.2118393 ,\n",
       "       1.2215748 , 1.262793  , 1.4069632 , 1.22817   , 1.4415491 ,\n",
       "       1.1016898 , 1.3938907 , 1.307992  , 1.2070634 , 1.3216383 ,\n",
       "       1.0453172 , 1.1295398 , 1.231464  , 1.1070796 , 1.3330405 ,\n",
       "       1.4071683 , 1.3417578 , 1.1053405 , 1.3283638 , 1.2303864 ,\n",
       "       1.0771611 , 1.3523879 , 1.2302749 , 1.2493776 , 1.0993737 ,\n",
       "       1.186365  , 1.3941694 , 1.3378413 , 1.1419718 , 1.1543882 ,\n",
       "       1.2257811 , 1.3567394 , 1.1487211 , 1.3024544 , 1.1947556 ,\n",
       "       1.3684566 , 1.1923627 , 1.457927  , 1.1680025 , 1.1899039 ,\n",
       "       0.97984004, 1.1429952 , 1.2227249 , 1.1955022 , 1.2890542 ,\n",
       "       1.3848182 , 1.399853  , 1.2717693 , 1.3301679 , 1.223235  ,\n",
       "       1.1666638 , 1.4411237 , 1.3488482 , 1.4141264 , 1.1985747 ,\n",
       "       1.170642  , 1.3858048 , 1.1339152 , 1.124953  , 1.144296  ,\n",
       "       1.3034697 , 1.4029335 , 1.2200799 , 1.5013976 , 1.2770277 ,\n",
       "       1.2204254 , 1.2207276 , 1.2996062 , 1.1463487 , 1.1748186 ,\n",
       "       1.4050727 , 1.3478634 , 1.1417304 , 1.2605014 , 1.1742703 ,\n",
       "       0.9372984 , 1.3376158 , 1.3154159 , 1.3922132 , 1.4189744 ,\n",
       "       1.3658719 , 1.2884372 , 1.4855334 , 1.3281777 , 1.1639129 ,\n",
       "       1.2886306 , 1.1537081 , 1.3974476 , 1.3529142 , 1.3299073 ,\n",
       "       1.1249604 , 1.2034112 , 1.1384858 , 1.4155983 , 1.0947988 ,\n",
       "       1.4087343 , 1.2402738 , 1.3131173 , 1.4591182 , 1.4619826 ,\n",
       "       1.3250256 , 1.4405705 , 1.1422206 , 1.2179215 , 1.3846372 ,\n",
       "       1.3120179 , 1.4021564 , 1.3460501 , 1.1558083 , 1.1304444 ,\n",
       "       1.1650414 , 1.4519509 , 1.2348698 , 1.3997111 , 0.963613  ,\n",
       "       1.2418988 , 1.144424  , 1.1869853 , 1.196751  , 1.2538221 ,\n",
       "       1.47693   , 1.121891  , 1.265987  , 1.3054019 , 1.0290073 ,\n",
       "       1.2010747 , 0.8898949 , 1.215977  , 1.2581829 , 1.295761  ,\n",
       "       1.1386783 , 1.2032169 , 1.0056033 , 1.1610856 , 1.248721  ,\n",
       "       1.1536573 , 1.2949535 , 1.4599926 , 1.0785139 , 1.3865964 ,\n",
       "       1.3452094 , 1.3310863 , 1.3196089 , 1.3206971 , 1.3920693 ,\n",
       "       1.1767509 , 1.4126815 , 1.3539584 , 1.3695996 , 1.3425558 ,\n",
       "       1.4044788 , 1.097726  , 1.1174953 , 1.2882088 , 1.2666887 ,\n",
       "       1.3301061 , 1.1355454 , 1.1355737 , 1.3009391 , 1.3115162 ,\n",
       "       1.4759673 , 1.3538057 , 1.4011661 , 1.3608868 , 1.290146  ,\n",
       "       1.3011558 , 1.0061045 , 1.2766432 , 1.3446258 , 1.1418121 ,\n",
       "       1.2980675 , 1.3624221 , 1.1366577 , 1.1349186 , 1.2150005 ,\n",
       "       1.2308716 , 1.2679913 , 1.1618786 , 1.3365821 , 1.34559   ,\n",
       "       1.4049209 , 1.2349708 , 1.3472099 , 1.330176  , 1.1895999 ,\n",
       "       1.2375605 , 1.3413557 , 1.1271642 , 1.1501288 , 1.3632951 ,\n",
       "       1.0603149 , 1.1361442 , 1.3850529 , 1.0908029 , 1.2624924 ,\n",
       "       1.3472202 , 1.2197323 , 1.3245723 , 1.2267795 , 1.379193  ,\n",
       "       1.0145007 , 1.4177501 , 1.4530295 , 1.0553406 , 1.3323916 ,\n",
       "       1.1336483 , 1.0599198 , 1.2701465 , 1.2098238 , 1.3365142 ,\n",
       "       1.2435336 , 1.1761703 , 1.3892145 , 1.2584208 , 1.1773237 ,\n",
       "       1.1075579 , 1.1015407 , 1.4255501 , 1.1406707 , 1.1842972 ,\n",
       "       1.2704473 , 1.0022422 , 1.3061453 , 1.4116448 , 1.346896  ,\n",
       "       1.3062478 , 1.1888392 , 1.3561858 , 1.3517368 , 1.2765279 ,\n",
       "       1.4098241 , 1.168026  , 1.262796  , 1.1293688 , 0.9802384 ,\n",
       "       1.2026945 , 1.3554629 , 1.2148424 , 1.4044311 , 1.2222241 ,\n",
       "       1.2507641 , 1.1253556 , 1.2364192 , 1.2394966 , 1.0543892 ,\n",
       "       1.3015472 , 1.0982561 , 1.4093199 , 1.161336  , 1.0997211 ,\n",
       "       1.3868105 , 1.2957443 , 1.4746119 , 1.0293726 , 1.3308167 ,\n",
       "       1.4217856 , 1.1762602 , 1.1963594 , 1.2697408 , 1.2893687 ,\n",
       "       1.2249722 , 1.2396151 , 1.4119784 , 1.1560977 , 1.2234652 ,\n",
       "       1.3024309 , 1.3445045 , 1.2371122 , 1.0307944 , 1.30457   ,\n",
       "       1.116524  , 1.107771  , 1.2253892 , 1.4516828 , 1.415091  ,\n",
       "       1.2038649 , 1.3640847 , 1.3519868 , 1.3928112 , 1.3308146 ,\n",
       "       1.2243763 , 1.2115164 , 1.3598505 , 1.2294651 , 1.2518033 ,\n",
       "       1.2191602 , 1.3977393 , 1.2707516 , 1.293274  , 1.3587346 ,\n",
       "       1.3406185 , 1.0805717 , 1.4153694 , 1.2661483 , 1.2770313 ,\n",
       "       1.4046894 , 1.1974595 , 1.1605116 , 1.1479512 , 1.2817075 ,\n",
       "       1.3687768 , 1.2630672 , 1.3091335 , 1.3514802 , 1.1651261 ,\n",
       "       1.3865175 , 1.330704  , 1.1735026 , 1.2454427 , 1.2317386 ,\n",
       "       1.2140863 , 1.1507027 , 1.3014715 , 1.2323747 , 1.2849874 ,\n",
       "       1.2512867 , 1.4301116 , 0.97034067, 1.232757  , 1.0931805 ,\n",
       "       1.4059331 , 1.4678485 , 1.1628748 , 1.0820997 , 1.4503441 ,\n",
       "       1.212673  , 1.2384254 , 1.304516  , 1.1001803 , 1.185905  ,\n",
       "       1.2144854 , 1.364009  , 1.5011654 , 1.2952328 , 1.3005949 ,\n",
       "       1.3307827 , 1.4081495 , 1.1747152 , 1.2089472 , 1.3291692 ,\n",
       "       1.344085  , 1.3452908 , 1.3401903 , 1.1352081 , 1.3353586 ,\n",
       "       1.3419318 , 1.1869559 , 1.1374831 , 1.2629768 , 1.2825785 ,\n",
       "       1.151992  , 1.2591003 , 1.5077299 , 1.3049444 , 1.2944278 ,\n",
       "       1.324028  , 1.5075648 , 1.1519758 , 1.2166156 , 1.2171977 ,\n",
       "       1.453394  , 1.4143018 , 1.2848014 , 1.3173084 , 1.0532337 ,\n",
       "       1.2407347 , 1.4158841 , 1.2677952 , 1.2374315 , 1.247448  ,\n",
       "       1.2706261 , 1.262073  , 1.0793862 , 1.1732326 , 1.1270089 ,\n",
       "       1.1908944 , 1.4018606 , 1.3290141 , 1.1856266 , 0.9165085 ,\n",
       "       1.3197447 , 1.1484843 , 1.2329553 , 1.4673765 , 1.1444975 ,\n",
       "       1.0808716 , 1.174108  , 1.104955  , 1.2820591 , 1.2190447 ,\n",
       "       1.1558411 , 1.1585231 , 1.3889265 , 1.0070043 , 1.2515264 ,\n",
       "       1.0479169 , 1.3209338 , 1.1565709 , 1.2171503 , 1.1567357 ,\n",
       "       1.4651519 , 1.3000638 , 1.1517767 , 1.1340586 , 1.3115181 ,\n",
       "       1.4596583 , 1.1219594 , 1.1170065 , 1.1066115 , 0.9635197 ,\n",
       "       1.1871308 , 1.1225592 , 1.1004428 , 1.1537719 , 1.2523012 ,\n",
       "       1.4700916 , 0.9225856 , 1.2051432 , 1.1943456 , 1.3244478 ,\n",
       "       1.4022902 , 1.176433  , 1.1450425 , 1.3149427 , 1.0251851 ,\n",
       "       1.1162963 , 1.4338745 , 1.2137277 , 1.3740929 , 1.0095173 ,\n",
       "       1.1715864 , 1.0152164 , 1.2643545 , 1.2686924 , 1.2514412 ,\n",
       "       1.3802509 , 1.1371826 , 1.3395422 , 1.1477072 , 1.2323107 ,\n",
       "       1.3612778 , 1.2235733 , 1.2495805 , 1.2849782 , 1.3150228 ,\n",
       "       1.2420605 , 1.4449425 , 1.3316195 , 1.2485752 , 1.2001544 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(model_save_nm, \"rb\"))\n",
    "\n",
    "loaded_model.predict(train_x.loc[:1000-1,].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务8：成功将 XGBoost 的预测结果文件提交到天池\n",
    "* 使用StratifiedKFold配合XGBoost完成模型的训练和预测\n",
    "* 在每折记录下模型对验证集和测试集的预测结果\n",
    "* 将多折测试集结果进行求均值，并写入csv提交到天池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 train score:5329.58431973079\n",
      "1 val score:5336.875206981723\n",
      "2 train score:5329.828708204683\n",
      "2 val score:5333.528000154876\n",
      "3 train score:5333.350929758723\n",
      "3 val score:5321.765059968439\n",
      "4 train score:5327.09992009937\n",
      "4 val score:5345.446365399552\n",
      "5 train score:5334.155382297118\n",
      "5 val score:5318.775678134664\n",
      "Train mae: 5334.155382297118\n",
      "val mae: 5331.278062127851\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "cnt = 0\n",
    "scores = []\n",
    "scores_train = []\n",
    "pred_test = []\n",
    "train_y = train['price']\n",
    "\n",
    "for train_index, val_index in skf.split(train_x, train_y):   \n",
    "    \n",
    "    cnt += 1 \n",
    "    X_train, X_val = train_x.iloc[train_index].values, train_x.iloc[val_index].values     \n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train = model_xgb.predict(X_train)\n",
    "    pred_val = model_xgb.predict(X_val)\n",
    "    \n",
    "    pred_test.append(model_xgb.predict(test.values).reshape(-1,).tolist())\n",
    "\n",
    "    score_train = mean_absolute_error(y_train, pred_train)\n",
    "    print(\"{} train score:{}\".format(cnt, score_train))\n",
    "    scores_train.append(score_train)\n",
    "    \n",
    "    score_val = mean_absolute_error(y_val, pred_val)\n",
    "    print(\"{} val score:{}\".format(cnt, score_val))\n",
    "    scores.append(score_val)\n",
    "    \n",
    "print('Train mae:', np.mean(score_train))\n",
    "print('val mae:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.round(np.mean(pred_test, axis=0),2)\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['SaleID'] = data1[data1['train']==0]['SaleID']\n",
    "sub_df['price'] = sub\n",
    "\n",
    "res_name = 'xgb_submit_'+str(time.time())+\".csv\"\n",
    "sub_df.to_csv('./submit/'+res_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## online result score:5441.9085"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务9：使用 LightGBM 模型完成训练和预测\n",
    "* 学会LightGBM模型的基础使用\n",
    "* 学会LightGBM模型的基础参数理解\n",
    "* 学会LightGBM模型的保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_x, train['price']) # 将数据保存到LightGBM二进制文件将使加载更快\n",
    "# lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)  # 创建验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # 设置提升类型\n",
    "    'objective': 'regression', # 目标函数\n",
    "    'metric': {'mae'},  # 评估函数 l1/mae\n",
    "    'num_leaves': 31,   # 叶子节点数\n",
    "    'learning_rate': 0.05,  # 学习速率\n",
    "    'feature_fraction': 0.9, # 建树的特征选择比例\n",
    "    'bagging_fraction': 0.8, # 建树的样本采样比例\n",
    "    'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "    'device':'gpu', #使用gpu\n",
    "    'verbose': 1 # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate feature names\n",
    "num_train, num_feature = train_x.shape\n",
    "\n",
    "feature_name = ['feature_' + str(col) for col in range(num_feature)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5761\n",
      "[LightGBM] [Info] Number of data points in the train set: 150000, number of used features: 317\n",
      "[LightGBM] [Info] Using GPU Device: GeForce RTX 2080 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (4.58 MB) transferred to GPU in 0.003554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5923.327333\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (3.67 MB) transferred to GPU in 0.002847 secs. 1 sparse feature groups\n",
      "[1]\ttraining's l1: 4765.06\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's l1: 4548.93\n",
      "[3]\ttraining's l1: 4341.37\n",
      "[4]\ttraining's l1: 4146.84\n",
      "[5]\ttraining's l1: 3961.89\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (3.66 MB) transferred to GPU in 0.002841 secs. 1 sparse feature groups\n",
      "[6]\ttraining's l1: 3784.99\n",
      "[7]\ttraining's l1: 3618.56\n",
      "[8]\ttraining's l1: 3460.86\n",
      "[9]\ttraining's l1: 3313.91\n",
      "[10]\ttraining's l1: 3171.66\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\ttraining's l1: 3171.66\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "# 训练 cv and train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10,\n",
    "                feature_name=feature_name,\n",
    "                valid_sets=lgb_train,  \n",
    "                early_stopping_rounds=10\n",
    "               ) # 训练数据需要参数列表和数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7ff6e809a610>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型保存与加载\n",
    "path = './model/'\n",
    "save_model_nm = \"lgb_model_\"+str(time.time())+'.txt'\n",
    "gbm.save_model(path+save_model_nm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/lgb_model_1633507153.7816436.txt\n"
     ]
    }
   ],
   "source": [
    "print(path+save_model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.Booster(model_file=path+save_model_nm)\n",
    "tmp_pred = gbm.predict(test.values, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21169.91144704,  3919.3190217 ,  6456.78185541, ...,\n",
       "        6183.13048652,  7927.30057534,  5160.35404101])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务10：成功将 LightGBM 的预测结果文件提交到天池\n",
    "* 使用StratifiedKFold配合LightGBM完成模型的训练和预测\n",
    "* 在每折记录下模型对验证集和测试集的预测结果\n",
    "* 将多折测试集结果进行求均值，并写入csv提交到天池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5745\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 313\n",
      "[LightGBM] [Info] Using GPU Device: GeForce RTX 2080 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (3.66 MB) transferred to GPU in 0.002923 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5922.060942\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (2.93 MB) transferred to GPU in 0.002568 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l1: 4537.81\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l1: 4114.9\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's l1: 4114.9\n",
      "1 train score:4099.4987501900105\n",
      "1 val score:4114.902934615285\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5745\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 313\n",
      "[LightGBM] [Info] Using GPU Device: GeForce RTX 2080 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (3.66 MB) transferred to GPU in 0.002943 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5922.246275\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (2.93 MB) transferred to GPU in 0.002557 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l1: 4523.67\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l1: 4100.36\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's l1: 4100.36\n",
      "2 train score:4102.012212098597\n",
      "2 val score:4100.355537717788\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5748\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 314\n",
      "[LightGBM] [Info] Using GPU Device: GeForce RTX 2080 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (3.66 MB) transferred to GPU in 0.002950 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5926.115742\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (2.93 MB) transferred to GPU in 0.002527 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l1: 4512.07\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l1: 4091.02\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's l1: 4091.02\n",
      "3 train score:4106.212229251726\n",
      "3 val score:4091.01909895043\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5744\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 313\n",
      "[LightGBM] [Info] Using GPU Device: GeForce RTX 2080 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (3.66 MB) transferred to GPU in 0.002944 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5919.187542\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (2.93 MB) transferred to GPU in 0.002554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l1: 4537.21\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l1: 4112.07\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's l1: 4112.07\n",
      "4 train score:4097.422892211534\n",
      "4 val score:4112.069585091346\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5751\n",
      "[LightGBM] [Info] Number of data points in the train set: 120000, number of used features: 315\n",
      "[LightGBM] [Info] Using GPU Device: GeForce RTX 2080 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (3.66 MB) transferred to GPU in 0.002963 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5927.026167\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 31 dense feature groups (2.93 MB) transferred to GPU in 0.002576 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l1: 4516.9\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l1: 4099.84\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2]\tvalid_0's l1: 4099.84\n",
      "5 train score:4106.597181967264\n",
      "5 val score:4099.837604454337\n",
      "Train mae: 4106.597181967264\n",
      "val mae: 4103.636952165837\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "cnt = 0\n",
    "scores = []\n",
    "scores_train = []\n",
    "pred_test = []\n",
    "train_y = train['price']\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # 设置提升类型\n",
    "    'objective': 'regression', # 目标函数\n",
    "    'metric': {'mae'},  # 评估函数 l1/mae\n",
    "#     'n_estimators':150,\n",
    "    'num_leaves': 300,   # 叶子节点数\n",
    "    'max_depth':7,\n",
    "    'learning_rate': 0.1,  # 学习速率\n",
    "    'feature_fraction': 0.9, # 建树的特征选择比例\n",
    "    'bagging_fraction': 0.8, # 建树的样本采样比例\n",
    "    'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "    'device':'gpu', #使用gpu\n",
    "#     'silent':True,\n",
    "    'verbose': 1 # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "}\n",
    "#  max_depth=7, \n",
    "#  n_estimators=150, \n",
    "#  num_leaves=300\n",
    "for train_index, val_index in skf.split(train_x, train_y):   \n",
    "    \n",
    "    cnt += 1 \n",
    "    X_train, X_val = train_x.iloc[train_index].values, train_x.iloc[val_index].values     \n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_val = lgb.Dataset(X_val, y_val)\n",
    "    \n",
    "    gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=2,\n",
    "                feature_name=feature_name,\n",
    "                valid_sets=lgb_val,  \n",
    "                early_stopping_rounds=5\n",
    "               ) \n",
    "    \n",
    "    pred_train = gbm.predict(X_train)\n",
    "    pred_val = gbm.predict(X_val)\n",
    "\n",
    "    pred_test.append(gbm.predict(test.values).reshape(-1,).tolist())\n",
    "\n",
    "    score_train = mean_absolute_error(y_train, pred_train)\n",
    "    print(\"{} train score:{}\".format(cnt, score_train))\n",
    "    scores_train.append(score_train)\n",
    "    \n",
    "    score_val = mean_absolute_error(y_val, pred_val)\n",
    "    print(\"{} val score:{}\".format(cnt, score_val))\n",
    "    scores.append(score_val)\n",
    "    \n",
    "print('Train mae:', np.mean(score_train))\n",
    "print('val mae:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.round(np.mean(pred_test, axis=0),2)\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['SaleID'] = data1[data1['train']==0]['SaleID']\n",
    "sub_df['price'] = sub\n",
    "\n",
    "res_name = 'lgb_submit_'+str(time.time())+\".csv\"\n",
    "sub_df.to_csv('./submit/'+res_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#online result score:5630.4628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务11：对 XGBoost、LightGBM 模型进行调参\n",
    "* 网格参数搜索、随机搜索参数、贝叶斯搜索参数\n",
    "* 使用Optuna完成模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 随机搜索参数\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# 贝叶斯搜索参数\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error,  make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5761\n",
      "[LightGBM] [Info] Number of data points in the train set: 150000, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score 5923.327333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5761\n",
      "[LightGBM] [Info] Number of data points in the train set: 150000, number of used features: 317\n",
      "[LightGBM] [Info] Start training from score 5923.327333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMRegressor(silent=False), n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.05, 0.1],\n",
       "                                        'max_depth': [4, 5, 7],\n",
       "                                        'n_estimators': [50, 100, 150],\n",
       "                                        'num_leaves': [300, 900, 1200]},\n",
       "                   scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网格搜索\n",
    "lg = lgb.LGBMRegressor(silent=False)\n",
    "# 候选参数\n",
    "param_dist = {\"max_depth\": [4,5, 7],\n",
    "              \"learning_rate\" : [0.01,0.05,0.1],\n",
    "              \"num_leaves\": [300,900,1200],\n",
    "              \"n_estimators\": [50, 100, 150]\n",
    "             }\n",
    "# 网格搜索\n",
    "grid_search_lgb = GridSearchCV(lg, n_jobs=-1, param_grid=param_dist, cv = 5, scoring=\"neg_mean_absolute_error\", verbose=1)\n",
    "grid_search_lgb.fit(train_x,train['price'])\n",
    "# 随机搜索参数\n",
    "random_search_lgb = RandomizedSearchCV(lg, n_jobs=-1, param_distributions=param_dist, scoring=\"neg_mean_absolute_error\", cv=5,  verbose=1)\n",
    "random_search_lgb.fit(train_x,train['price'])\n",
    "# grid_search.best_estimator_, grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(max_depth=7, n_estimators=150, num_leaves=300, silent=False),\n",
       " -641.6712418116799)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lgb.best_estimator_, grid_search_lgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LGBMRegressor(learning_rate=0.05, max_depth=7, n_estimators=150, num_leaves=900,\n",
       "               silent=False),\n",
       " -658.4956476360721)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_lgb.best_estimator_, random_search_lgb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_ch... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-729.5   \u001b[0m | \u001b[0m 40.85   \u001b[0m | \u001b[0m 86.89   \u001b[0m | \u001b[0m 31.0    \u001b[0m | \u001b[0m 0.6323  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-666.7   \u001b[0m | \u001b[95m 71.84   \u001b[0m | \u001b[95m 84.31   \u001b[0m | \u001b[95m 66.97   \u001b[0m | \u001b[95m 0.9374  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-831.9   \u001b[0m | \u001b[0m 81.21   \u001b[0m | \u001b[0m 3.649   \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 0.989   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-747.5   \u001b[0m | \u001b[0m 17.28   \u001b[0m | \u001b[0m 9.202   \u001b[0m | \u001b[0m 25.35   \u001b[0m | \u001b[0m 0.9181  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.345e+0\u001b[0m | \u001b[0m 77.21   \u001b[0m | \u001b[0m 12.23   \u001b[0m | \u001b[0m 2.209   \u001b[0m | \u001b[0m 0.9133  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-860.4   \u001b[0m | \u001b[0m 34.27   \u001b[0m | \u001b[0m 40.52   \u001b[0m | \u001b[0m 10.3    \u001b[0m | \u001b[0m 0.3192  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-748.7   \u001b[0m | \u001b[0m 69.87   \u001b[0m | \u001b[0m 10.51   \u001b[0m | \u001b[0m 25.2    \u001b[0m | \u001b[0m 0.4382  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-759.8   \u001b[0m | \u001b[0m 8.489   \u001b[0m | \u001b[0m 72.57   \u001b[0m | \u001b[0m 23.11   \u001b[0m | \u001b[0m 0.8514  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-662.4   \u001b[0m | \u001b[95m 19.74   \u001b[0m | \u001b[95m 43.52   \u001b[0m | \u001b[95m 71.89   \u001b[0m | \u001b[95m 0.3399  \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-658.5   \u001b[0m | \u001b[95m 16.4    \u001b[0m | \u001b[95m 44.85   \u001b[0m | \u001b[95m 77.74   \u001b[0m | \u001b[95m 0.3966  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-664.6   \u001b[0m | \u001b[0m 71.14   \u001b[0m | \u001b[0m 84.06   \u001b[0m | \u001b[0m 68.44   \u001b[0m | \u001b[0m 0.3203  \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-655.6   \u001b[0m | \u001b[95m 27.5    \u001b[0m | \u001b[95m 57.33   \u001b[0m | \u001b[95m 77.81   \u001b[0m | \u001b[95m 0.4614  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-669.0   \u001b[0m | \u001b[0m 12.25   \u001b[0m | \u001b[0m 60.1    \u001b[0m | \u001b[0m 68.61   \u001b[0m | \u001b[0m 0.6478  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-657.8   \u001b[0m | \u001b[0m 12.46   \u001b[0m | \u001b[0m 63.62   \u001b[0m | \u001b[0m 88.97   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-658.6   \u001b[0m | \u001b[0m 22.5    \u001b[0m | \u001b[0m 78.39   \u001b[0m | \u001b[0m 77.82   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-663.8   \u001b[0m | \u001b[0m 45.24   \u001b[0m | \u001b[0m 75.49   \u001b[0m | \u001b[0m 69.52   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m-645.6   \u001b[0m | \u001b[95m 37.91   \u001b[0m | \u001b[95m 72.52   \u001b[0m | \u001b[95m 92.88   \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-651.1   \u001b[0m | \u001b[0m 45.69   \u001b[0m | \u001b[0m 92.84   \u001b[0m | \u001b[0m 85.01   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-645.9   \u001b[0m | \u001b[0m 60.69   \u001b[0m | \u001b[0m 74.71   \u001b[0m | \u001b[0m 92.1    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-652.0   \u001b[0m | \u001b[0m 54.65   \u001b[0m | \u001b[0m 53.58   \u001b[0m | \u001b[0m 82.45   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-638.3   \u001b[0m | \u001b[95m 36.68   \u001b[0m | \u001b[95m 46.74   \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-719.8   \u001b[0m | \u001b[0m 93.01   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 34.48   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-651.4   \u001b[0m | \u001b[0m 40.94   \u001b[0m | \u001b[0m 30.36   \u001b[0m | \u001b[0m 83.73   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[95m 24      \u001b[0m | \u001b[95m-637.3   \u001b[0m | \u001b[95m 59.75   \u001b[0m | \u001b[95m 36.62   \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-645.2   \u001b[0m | \u001b[0m 77.99   \u001b[0m | \u001b[0m 54.07   \u001b[0m | \u001b[0m 94.45   \u001b[0m | \u001b[0m 0.3024  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-654.5   \u001b[0m | \u001b[0m 72.29   \u001b[0m | \u001b[0m 32.14   \u001b[0m | \u001b[0m 78.84   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-664.0   \u001b[0m | \u001b[0m 79.93   \u001b[0m | \u001b[0m 57.25   \u001b[0m | \u001b[0m 68.78   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-641.5   \u001b[0m | \u001b[0m 59.17   \u001b[0m | \u001b[0m 11.06   \u001b[0m | \u001b[0m 94.5    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m-636.3   \u001b[0m | \u001b[95m 83.14   \u001b[0m | \u001b[95m 22.96   \u001b[0m | \u001b[95m 100.0   \u001b[0m | \u001b[95m 0.1     \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-646.9   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 38.78   \u001b[0m | \u001b[0m 87.12   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "# 贝叶斯搜索\n",
    "def rf_cv_lgb(num_leaves, max_depth, subsample, min_child_samples):\n",
    "    val = cross_val_score(\n",
    "        lgb.LGBMRegressor(objective = 'regression_l1',\n",
    "            num_leaves=int(num_leaves),\n",
    "            max_depth=int(max_depth),\n",
    "            subsample = subsample,\n",
    "            min_child_samples = int(min_child_samples)\n",
    "        ),\n",
    "        X=train_x, y=train['price'], verbose=0, cv = 5, scoring=make_scorer(mean_absolute_error)\n",
    "    ).mean()\n",
    "    return 1 - val\n",
    "rf_bo_lgb = BayesianOptimization(\n",
    "    rf_cv_lgb,\n",
    "    {\n",
    "    'num_leaves': (2, 100),\n",
    "    'max_depth': (2, 100),\n",
    "    'subsample': (0.1, 1),\n",
    "    'min_child_samples' : (2, 100)\n",
    "    }\n",
    ")\n",
    "rf_bo_lgb.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBRFRegressor(\n",
    "        n_estimators=120, \n",
    "        learning_rate=0.1,\n",
    "        gamma=0, \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.9,\n",
    "        max_depth=7\n",
    ")\n",
    "param_dist = {\"n_estimators\":[50, 100, 150],\n",
    "              \"max_depth\": [4,5, 7],\n",
    "              \"learning_rate\" : [0.01,0.05,0.1]\n",
    "             }\n",
    "grid_search_xgb = GridSearchCV(model_xgb, n_jobs=-1, param_grid=param_dist, cv = 5, scoring=\"neg_mean_absolute_error\", verbose=1)\n",
    "grid_search_xgb.fit(train_x,train['price'])\n",
    "\n",
    "# 随机搜索参数\n",
    "random_search_xgb = RandomizedSearchCV(model_xgb, n_jobs=-1, param_grid=param_dist, cv = 5, scoring=\"neg_mean_absolute_error\", verbose=1)\n",
    "random_search_xgb.fit(train_x,train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_xgb.best_estimator_, grid_search_xgb.best_score_)\n",
    "print(random_search_xgb.best_estimator_, random_search_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贝叶斯搜索\n",
    "def rf_cv_xgb(num_leaves, max_depth, subsample, min_child_samples):\n",
    "    val = cross_val_score(\n",
    "        xgb.XGBRFRegressor(\n",
    "            n_estimators=120, \n",
    "            learning_rate=0.1,\n",
    "            gamma=0, \n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.9,\n",
    "            max_depth=7\n",
    "            ),\n",
    "        X=train_x, y=train['price'], verbose=0, cv = 5, scoring=make_scorer(mean_absolute_error)\n",
    "    ).mean()\n",
    "    return 1 - val\n",
    "rf_bo_xgb = BayesianOptimization(\n",
    "    rf_cv_lgb,\n",
    "    {\n",
    "    \"n_estimators\":[50, 100, 150],\n",
    "    \"max_depth\": [4,5, 7],\n",
    "     \"learning_rate\" : [0.01,0.05,0.1]\n",
    "    }\n",
    ")\n",
    "print(rf_bo_xgb.maximize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务12：使用交叉验证 + Stacking 过程完成模型集成\n",
    "* 使用Stacking完成模型集成\n",
    "* 将多折测试集结果进行求均值，并写入csv提交到天池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(train_x, train['price'], test_size=0.3, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train = np.zeros((X.shape[0], 1)) #\n",
    "stacking_test = np.zeros((X_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # 设置提升类型\n",
    "    'objective': 'regression', # 目标函数\n",
    "    'metric': {'mae'},  # 评估函数 l1/mae\n",
    "#     'n_estimators':150,\n",
    "    'num_leaves': 300,   # 叶子节点数\n",
    "    'max_depth':7,\n",
    "    'learning_rate': 0.1,  # 学习速率\n",
    "    'feature_fraction': 0.9, # 建树的特征选择比例\n",
    "    'bagging_fraction': 0.8, # 建树的样本采样比例\n",
    "    'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "    'device':'gpu', #使用gpu\n",
    "#     'silent':True,\n",
    "    'verbose': 1 # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5折stacking\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits)\n",
    "\n",
    "i = 0\n",
    "# 训练lgb模型\n",
    "stacking_test_j = np.zeros((X_predict.shape[0], n_splits))\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_index].values, X.iloc[val_index].values     \n",
    "    y_train, y_val = y.iloc[train_index].values, y.iloc[val_index].values\n",
    "    # 5-Fold交叉训练，使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_val = lgb.Dataset(X_val, y_val)\n",
    "    gbm = lgb.train(params,\n",
    "            lgb_train,\n",
    "            num_boost_round=20,\n",
    "            feature_name=feature_name,\n",
    "            valid_sets=lgb_val,  \n",
    "            early_stopping_rounds=5\n",
    "           ) \n",
    "\n",
    "    y_submission = gbm.predict(X_val)\n",
    "    stacking_train[val_index, 0] = y_submission # 保存子模型对交叉验证集的预测结果\n",
    "    stacking_test_j[:, i] = gbm.predict(X_test) # 交叉子模型预测训练集\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对于测试集，直接用这k个模型的预测值均值作为新的特征。\n",
    "stacking_test = stacking_test_j.mean(1)\n",
    "print(\"val mae score: %f\" % mean_absolute_error(y_predict, stacking_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression(solver='lbfgs')\n",
    "clf.fit(stacking_train, y)\n",
    "y_submission = clf.predict(dataset_blend_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
